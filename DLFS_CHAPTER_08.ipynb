{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 08 딥러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝은 층을 깊게 한 심층 신경망이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 더 깊게"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 더 깊은 신경망으로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-1.png' width=70%>\n",
    "<center>**그림 8-1** 손글씨 숫자를 인식하는 심층 CNN</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 신경망은 VGG 신경망을 참고한 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "합성곱 계층은 모두 3 $\\times$ 3 크기의 작은 필터로, 층이 깊어지면서 채널 수가 더 늘어나는 것이 특징이다. 합성곱 계층의 채널 수는 앞 계층에서부터 순서대로 16, 16, 32, 32, 64, 64로 늘어난다. 또 그림과 같이 풀링 계층을 추가하여 중간 데이터의 공간 크기를 점차 줄여나간다. 그리고 마지막 단의 완전연결 계층에서는 드롭아웃 계층을 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가중치 초깃값으로 He 초깃값을 사용하고, 가중치 매개변수 갱신에는 Adam을 이용한다. 이상을 정리하면 이 신경마의 특징은 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3$\\times$3의 작은 필터를 사용한 합성곱 계층\n",
    "- 활성화 함수는 ReLU\n",
    "- 완전연결 계층 뒤에 드롭아웃 계층 사용\n",
    "- Adam을 사용해 최적화\n",
    "- 가중치 초기값은 'He 초기값'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.2 정확도를 더 높이려면"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<What is the class of this image?> 웹 사이트는 다양한 데이터셋을 대상으로 그동안 논문 등에서 발표한 기법들의 정확도 순위를 정리해 두었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-3.png' width=70%>\n",
    "<center>**그림 8-3** MNIST 데이터셋에 대한 각 기법의 순위(2016년 12월 시점)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "순위 상위권의 대부분은 'Neural Networks'나 'Deep', 'Convolutional' 이라는 키워드가 돋보인다. 대부분 CNN을 기초로 한 기법들이 정렴했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE_** MNIST 데이터셋에 대해서는 층을 아주 깊게 하지 않고도 (현 시점에서는)최고 수준의 결과가 나온다. 이는 손글씨 숫자라는 문제가 비교적 단순해서 신경망의 표현력을 극한까지 높일 필요가 없기 때문이다. 그래서 층을 깊게 해 줘도 혜택이 적은 것이다. 반면 대규모 일반 사물 인식에서는 문제가 훨씬 복잡해지므로 층을 깊게 하면 정확도를 크게 끌어올릴 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그림 8-3의 상위 기법들을 참고하면 정확도를 더 높일 수 있는 기술이나 힌트를 발견할 수 있다. 예를 들어 앙상블 학습, 학습률 감소, 데이터 확장 등이 정확도 향상에 공헌하고 있다. 특히 데이터 확장은 손쉬운 방법이면서도 정확도 개선에 아주 효과적이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 확장(data augmentation)은 입력 이미지(훈련 이미지)를 알고리즘을 동원해 인위적으로 확장한다. 아래와 같이 입력 이미지를 회전하거나 세로로 이동하는 등 미세한 변화를 주어 이미지의 개수를 늘리는 것이다. 이는 데이터가 특히 몇개 없을 때 효과적인 수단이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-4.png' width=70%>\n",
    "<center>**그림 8-4** 데이터 확장의 예</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 확장은 위와 같은 변형 외에도 다양한 방법으로 이미지를 확장할 수 있다. 예를 들어 이미지 일부를 잘라내는 crop이나 좌우를 뒤집는 flip\\*등이 있겠다. (다만 flip은 이미지의 대칭성을 고려하지 않아도 되는 경우에만 사용할 수 있다.)\n",
    "\n",
    "일반적인 이미지에는 밝기 등의 외형 변화나 확대, 축소 등의 스케일 변화도 효과적이다. 어쨌든 데이터 확장을 동원해 훈련 이미지의 개수를 늘릴 수 있다면 딥러닝의 인식 수준을 개선할 수 있다. 이를 쉬운 '트릭'이라 가볍게 생각할지도 모르겠지만, 멋진 결과를 가져오는 경우가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.3 깊게 하는 이유"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "층을 깊게 해야 하는 것이 왜 중요한가에 대한 이론적인 근거는 아직 많이 부족한 것이 사실이다. 그래도 지금까지의 연구와 실험 결과를 바탕으로 설명하는 것은 몇 가지 있다.(다소 직관적이긴 하다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ILSVRC로 대표되는 대규모 이미지 인식 대회의 결과에서 보면 이 대회에서 상위를 차지한 기법 대부분은 딥러닝 기반이며, 그 경향은 신경망을 더 깊게 만드는 방향으로 가고 있다. 층의 깊이에 비례해 정확도가 좋아지는 것이다.\n",
    "\n",
    "이어서 층을 깊게 할 때의 이점으로는, 신경망의 매개변수의 수가 줄어든다는 것이다. 층을 깊게 한 신경망은 깊지 않은 경우보다 적은 매개변수로 같은 수준(혹은 그 이상)의 표현력을 달성할 수 있다. 합성곱 연산에서의 필터 크기에 주목해 생각해 보자. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-5.png' width=70%>\n",
    "<center>**그림 8-5** 5 $\\times$ 5 합성곱 연산의 예</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 그림에서 각각의 출력 노드는 입력 데이터의 5 $\\times$ 5크기 영역에서 계산된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-6.png' width=70%>\n",
    "<center>**그림 8-6** 3$\\times$3 합성곱 계층을 2회 반복한 예</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 그림처럼 3$\\times$3 합성곱 연산을 2회 반복하는 경우를 생각해 보자. 이 경우 출력 노드 하나는 중간 데이터의 3$\\times$3 영역에서 계산된다. 그리고 그 중간 데이터의 3$\\times$3 영역은 그전 입력 데이터의 5$\\times$5 크기의 역역에서 계산되어 나오는 것을 알 수 있다. 즉, 위 [그림 8-6]의 출력 데이터는 입력 데이터의 5$\\times$5 영역을 '보고' 계산하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 $\\times$ 5의 합성곱 연산 1회는 3 $\\times$ 3의 합성곱 연산을 2회 수행하여 대체할 수 있다. 전자의 매개변수 수는 25개(5 $\\times$ 5)인 반면, 후자는 총 18개 (2 $\\times$ 3 $\\times$ 3)이다. 이러한 매개변수 수는 층을 반복할수록 적어진다. 그리고 그 개수의 차이는 층이 깊어질수록 커진다. \n",
    "\n",
    "가령 3 $\\times$ 3의 합성곱 연산을 3회 반복하면 매개변수는 모두 27개가 되지만, 같은 크기의 영역을 1회의 합성곱 연산으로 '보기' 위해서는 7 $\\times$ 7 크기의 필터, 즉 매개변수 49개 팔요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE_** 작은 필터를 겹쳐 신경망을 깊게 할 때의 장점은 매개변수 수를 줄여 넓은 수용 영역을 소화할 수 있다는데 있다.(수용 영역은 뉴런에 변화를 일으키는 국소적인 공간 영역이다.) 게다가 층을 거듭하면서 ReLU등의 활성화 함수를 합성곱 계층 사이에 끼움으로써 신경망의 표현력이 개선된다. 이는 활성화 함수가 신경망에 '비선형' 힘을 가하고, 비선형 함수가 겹치면서 더 복잡한 것도 표현할 수 있게 되기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "핛브의 효율성도 층을 깊게 하는 것의 이점이다. 층을 깊게 함으로써 학습 데이터의 양을 줄여 학습을 고속으로 수행할 수 있다는 점이다.\n",
    "\n",
    "가령 CNN의 합성곱 계층이 정보를 계층적으로 추출하고 있음을 설명했다. 앞단의 합성곱 계층에서는 에지 등의 단순한 패턴에 뉴런이 더 반응하고 층이 깊어지면서 텍스처와 사물의 일부와 같이 점차 복잡한 것에 반응한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'개'를 인식하는 문제를 생각해 보자. 얕은 신경망에서 해결하려면 합성곱 계층은 개의 특징 대부분을 한번에 '이해'해야 한다. 견종도 다양하고 어느 각도에서 찍은 사진이냐에 따라 완전히 다르게 보일 수 있다. 그래서 개의 특징을 이해하려면 변화가 풍부하고 많은 학습 데이터가 필요하고, 결과적으로 학습 시간이 오래 걸린다.\n",
    "\n",
    "그러나 신경망을 깊게 하면 학습해야 할 문제를 계층적으로 분해할 수 있다. 각 층이 학습해야 할 문제를 보다 단순한 문제로 대체할 수 있는 것이다. 예를 들어 처음 층은 에지 학습에 전념하여 적은 데이터로 효율적으로 학습할 수 있다. 개가 등작하는 이미지보다 에지를 포함한 이미지는 만혹, 에지의 패턴을 개라는 패턴으로 구조가 훨씬 간단하기 때문이다.\n",
    "\n",
    "또, 층을 깊게 하면 정보를 계층적으로 전달할 수 있다는 점도 중요하다. 예를 들어 에지를 추출한 층의 다음 층은 에지 정보를 쓸 수 있고, 더 고도의 패턴을 효과적으로 학습하리라 기대할 수 있다. 즉, 층을 깊이 함으로써 각 층이 학습해야 할 문제를 '풀기 쉬운 단순한 문제'로 분해할 수 있어 효율적으로 학습하리라 기대할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 딥러닝의 초기 역사"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2012년 AlexNet이 압도적인 성적으로 우승하면서 이미지 인식에 대한 접근법을 뿌리부터 뒤흔들었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.1 이미지넷"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-7.png' width=70%>\n",
    "<center>**그림 8-7** 대규모 데이터셋 ImageNet의 데이터들</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지넷은 100만장이 넘는 이미지를 담고 있는 데이터셋이다. 각 이미지에는 레이블(클래스 이름)이 붙어 있따. 매년 열리는 ILSVRC대회에는 시험 항목이 몇 가지 있는데, 그 중 하나가 분류(classification)이다. 분류 부문에서는 1,000개의 클래스를 제대로 분류하는지를 겨룬다. 최근 분류 시험 결과는 다음과 같다. 아래는 **톱-5 오류**를 뜻하는데, 이는 확률이 가장 높다고 생각하는 후보 클래스 5개 안에 정답이 포함되지 않은, 즉 5개 모두가 틀린 비율을 뜻한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-8.png' width=70%>\n",
    "<center>**그림 8-8** ILSVRC 최우수 팀의 성적 추이: 세로축은 오류율, 가로축은 연도, 가로축의 괄호 안은 팀 이름(또는 기법 이름)</center>\n",
    "<center>이미지넷 분류 톱-5 오류</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[그림 8-8]에서 주목할 점은 2012년 이후 선두는 항상 딥러닝 방식이었다는 것이다. 실제로 2012년 AlexNet의 오류율이 크게 낮아졌고, 그 이후 딥러닝을 활ㅇ요한 기법이 꾸준히 정확도를 개선해 왔다. 특히 2015년에는 150층이 넘는 심층 신경망인 ResNet이 오류율을 3.5%까지 낮추었다. 이는 인간의 인식 능력을 넘어선 것이다. 특히 VGG, GoogLeNet, ResNet은 특히 유명하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.2 VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG는 합성곱 계층과 풀링 계층으로 구성되는 '기본적'인 CNN이다. 다만 비중 있는 층(합성곱 계층, 완전연결 계층)을 모두 16층(혹은 19층)으로 심화한 것이 특징이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-9.png' width=70%>\n",
    "<center>**그림 8-9** VGG</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG에서 주목할 점은 3 $\\times$ 3 의 작은 필터를 사용한 합성곱 계층을 연속으로 거친다는 것이다. 그림에서 보듯 합성곱 계층을 2~4회 연속으로 풀링 계층을 두어 크기를 절반으로 줄이는 처리를 반복합니다. 그리고 마지막에는 완전연결 계층을 통과시켜 결과를 출력한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE_** VGG는 2014년 대회에서 2위에 올랐다. 성능 면에서는 1위인 GoogLeNet에 뒤지지만 VGG는 구성이 간단하여 응용하기가 좋다. 그래서 많은 기술자가 VGG 기반의 신경망을 즐겨 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.3 GoogLeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GoogLeNet의 구성은 아래 그림과 같다. 그림의 사각형이 합성곱 계층과 풀링 계층등의 계층을 나타낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-10.png' width=90%>\n",
    "<center>**그림 8-10** VGG</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "매우 복잡해 보이지만 기본적으로 보아온 CNN과 다르지 않다. 단, GoogLeNet은 세로 방향 깊이뿐 아니라 가로 방향도 깊다는 점이 특징이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GoogLeNet에는 가로 방향에 '폭'이 있다. 이를 인셉션 구조라 하며, 그 기반 구조는 [그림 8-11]과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-11.png' width=80%>\n",
    "<center>**그림 8-11** GoogLeNet의 인셉션 구조</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인셉션 구조는 앞의 그림과 같이 다른 필터(와 풀링)를 여러개 적용하겨 그 결과를 결합한다. 이 인셉션 구조를 하나의 빌딩 블록(구성요소)로 사용하는 것이 GoogLeNet의 특징인 것이다. \n",
    "\n",
    "또, GoogLeNet에서는 1 $\\times$ 1 크기의 필터를 사용한 합성곱 계층을 많은 곳에서 사용한다. 이 1 $\\times$ 1 의 합성곱 연산은 채널 쪽으로 크기를 줄이는 것으로, 매개변수 제거와 고속 처리에 기여한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.4 ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ResNet**은 마이크로소프트의 팀이 개발한 네트워크이다. 그 특징은 지금까지보다 층을 더 깊게 할 수 있는 특별한 '장치'에 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보통 층을 깊게 하는 것이 성능 향상에 중요하다는 것은 알고 있지만, 딥러닝의 학습에서는 층이 지나치게 깊으면 학습이 잘 되지 않고, 오히려 성능이 떨어지는 경우도 많다. ResNet에서는 그런 문제를 해결하기 위해 **스킵 연결**(skip connection)을 도입한다. 이 구조가 층의 깊이에 비례해 성능을 향상시킬 수 있게 한 핵심이다.\n",
    "\n",
    "스킵 연결이란 [그림 8-12]와 같이 입력 데이터를 합성곱 계층을 건너뛰어 출력에 바로 더하는 구조를 말한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-12.png' width=70%>\n",
    "<center>**그림 8-12** ResNet의 구성요소: 'weight layer'는 합성곱 계층을 말한다. </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[그림 8-12]에서는 입력 x를 연속한 두 합성곱 계층을 건너뛰어 출력에 바로 연결한다. 이 단축 경로가 없었다면 두 합성곱 계층의 출력이 F(x)가 되나, 스킵 연결로 인해 F(x) + x가 되는 것이 핵심이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note_** 스킵 연결은 입력 데이터를 '그대로' 흘리는 것으로, 역전파 때도 상류의 기울기를 그대로 하류로 보낸다. 여기에서의 핵심은 상류의 기울기에 아무런 수정도 가하지 않고 '그대로' 흘린다는 것이다. 그래서 스킵 연결로 기울이가 작아지거나 지나치게 커질 걱정 없이 앞 층에 '의미 있는 기울기'가 전해지리라 기대할 수 있다. 층을 깊게 할수록 기울기가 작아지는 소실 문제를 이 스킵 연결이 줄여주는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet은 먼저 설명한 VGG 신경망을 기반으로 스킵 연결을 도입하여 층을 깊게 하였다. 그 결과는 [그림 8-13]처럼 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-13.png' width=90%>\n",
    "<center>**그림 8-13** ResNet: 블록이 3 $\\times$ 3인 합성곱 계층에 대응. 층을 건너뛰는 스킵 연결이 특징이다. </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[그림 8-13]과 같이 ResNet은 합성곱 계층을 2개 층마다 건너뛰면서 층을 깊게 한다. 실험결과 150층 이상으로 해도 정확도가 오른느 모습을 확인할 수 있다. 긜고 ILSVRC 대회에서는 톱-5 오류율이 겨울 3.5%라는 경이적인 결과를 냇다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE_** 이미지넷이 제공하는 거대한 데이터셋으로 학습한 가중치 값들은 실제 제품에 활용해도 효과적이고, 또 많이들 그렇게 이용하고 있다. 이를 **전이 학습**(transfer learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
