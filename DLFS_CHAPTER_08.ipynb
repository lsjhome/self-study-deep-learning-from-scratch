{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 08 딥러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝은 층을 깊게 한 심층 신경망이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 더 깊게"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 더 깊은 신경망으로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-1.png' width=70%>\n",
    "<center>**그림 8-1** 손글씨 숫자를 인식하는 심층 CNN</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 신경망은 VGG 신경망을 참고한 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "합성곱 계층은 모두 3 $\\times$ 3 크기의 작은 필터로, 층이 깊어지면서 채널 수가 더 늘어나는 것이 특징이다. 합성곱 계층의 채널 수는 앞 계층에서부터 순서대로 16, 16, 32, 32, 64, 64로 늘어난다. 또 그림과 같이 풀링 계층을 추가하여 중간 데이터의 공간 크기를 점차 줄여나간다. 그리고 마지막 단의 완전연결 계층에서는 드롭아웃 계층을 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가중치 초깃값으로 He 초깃값을 사용하고, 가중치 매개변수 갱신에는 Adam을 이용한다. 이상을 정리하면 이 신경마의 특징은 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3$\\times$3의 작은 필터를 사용한 합성곱 계층\n",
    "- 활성화 함수는 ReLU\n",
    "- 완전연결 계층 뒤에 드롭아웃 계층 사용\n",
    "- Adam을 사용해 최적화\n",
    "- 가중치 초기값은 'He 초기값'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.2 정확도를 더 높이려면"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<What is the class of this image?> 웹 사이트는 다양한 데이터셋을 대상으로 그동안 논문 등에서 발표한 기법들의 정확도 순위를 정리해 두었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-3.png' width=70%>\n",
    "<center>**그림 8-3** MNIST 데이터셋에 대한 각 기법의 순위(2016년 12월 시점)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "순위 상위권의 대부분은 'Neural Networks'나 'Deep', 'Convolutional' 이라는 키워드가 돋보인다. 대부분 CNN을 기초로 한 기법들이 정렴했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE_** MNIST 데이터셋에 대해서는 층을 아주 깊게 하지 않고도 (현 시점에서는)최고 수준의 결과가 나온다. 이는 손글씨 숫자라는 문제가 비교적 단순해서 신경망의 표현력을 극한까지 높일 필요가 없기 때문이다. 그래서 층을 깊게 해 줘도 혜택이 적은 것이다. 반면 대규모 일반 사물 인식에서는 문제가 훨씬 복잡해지므로 층을 깊게 하면 정확도를 크게 끌어올릴 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그림 8-3의 상위 기법들을 참고하면 정확도를 더 높일 수 있는 기술이나 힌트를 발견할 수 있다. 예를 들어 앙상블 학습, 학습률 감소, 데이터 확장 등이 정확도 향상에 공헌하고 있다. 특히 데이터 확장은 손쉬운 방법이면서도 정확도 개선에 아주 효과적이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 확장(data augmentation)은 입력 이미지(훈련 이미지)를 알고리즘을 동원해 인위적으로 확장한다. 아래와 같이 입력 이미지를 회전하거나 세로로 이동하는 등 미세한 변화를 주어 이미지의 개수를 늘리는 것이다. 이는 데이터가 특히 몇개 없을 때 효과적인 수단이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-4.png' width=70%>\n",
    "<center>**그림 8-4** 데이터 확장의 예</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 확장은 위와 같은 변형 외에도 다양한 방법으로 이미지를 확장할 수 있다. 예를 들어 이미지 일부를 잘라내는 crop이나 좌우를 뒤집는 flip\\*등이 있겠다. (다만 flip은 이미지의 대칭성을 고려하지 않아도 되는 경우에만 사용할 수 있다.)\n",
    "\n",
    "일반적인 이미지에는 밝기 등의 외형 변화나 확대, 축소 등의 스케일 변화도 효과적이다. 어쨌든 데이터 확장을 동원해 훈련 이미지의 개수를 늘릴 수 있다면 딥러닝의 인식 수준을 개선할 수 있다. 이를 쉬운 '트릭'이라 가볍게 생각할지도 모르겠지만, 멋진 결과를 가져오는 경우가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.3 깊게 하는 이유"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "층을 깊게 해야 하는 것이 왜 중요한가에 대한 이론적인 근거는 아직 많이 부족한 것이 사실이다. 그래도 지금까지의 연구와 실험 결과를 바탕으로 설명하는 것은 몇 가지 있다.(다소 직관적이긴 하다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ILSVRC로 대표되는 대규모 이미지 인식 대회의 결과에서 보면 이 대회에서 상위를 차지한 기법 대부분은 딥러닝 기반이며, 그 경향은 신경망을 더 깊게 만드는 방향으로 가고 있다. 층의 깊이에 비례해 정확도가 좋아지는 것이다.\n",
    "\n",
    "이어서 층을 깊게 할 때의 이점으로는, 신경망의 매개변수의 수가 줄어든다는 것이다. 층을 깊게 한 신경망은 깊지 않은 경우보다 적은 매개변수로 같은 수준(혹은 그 이상)의 표현력을 달성할 수 있다. 합성곱 연산에서의 필터 크기에 주목해 생각해 보자. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-5.png' width=70%>\n",
    "<center>**그림 8-5** 5 $\\times$ 5 합성곱 연산의 예</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 그림에서 각각의 출력 노드는 입력 데이터의 5 $\\times$ 5크기 영역에서 계산된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-6.png' width=70%>\n",
    "<center>**그림 8-6** 3$\\times$3 합성곱 계층을 2회 반복한 예</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 그림처럼 3$\\times$3 합성곱 연산을 2회 반복하는 경우를 생각해 보자. 이 경우 출력 노드 하나는 중간 데이터의 3$\\times$3 영역에서 계산된다. 그리고 그 중간 데이터의 3$\\times$3 영역은 그전 입력 데이터의 5$\\times$5 크기의 역역에서 계산되어 나오는 것을 알 수 있다. 즉, 위 [그림 8-6]의 출력 데이터는 입력 데이터의 5$\\times$5 영역을 '보고' 계산하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 $\\times$ 5의 합성곱 연산 1회는 3 $\\times$ 3의 합성곱 연산을 2회 수행하여 대체할 수 있다. 전자의 매개변수 수는 25개(5 $\\times$ 5)인 반면, 후자는 총 18개 (2 $\\times$ 3 $\\times$ 3)이다. 이러한 매개변수 수는 층을 반복할수록 적어진다. 그리고 그 개수의 차이는 층이 깊어질수록 커진다. \n",
    "\n",
    "가령 3 $\\times$ 3의 합성곱 연산을 3회 반복하면 매개변수는 모두 27개가 되지만, 같은 크기의 영역을 1회의 합성곱 연산으로 '보기' 위해서는 7 $\\times$ 7 크기의 필터, 즉 매개변수 49개 팔요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE_** 작은 필터를 겹쳐 신경망을 깊게 할 때의 장점은 매개변수 수를 줄여 넓은 수용 영역을 소화할 수 있다는데 있다.(수용 영역은 뉴런에 변화를 일으키는 국소적인 공간 영역이다.) 게다가 층을 거듭하면서 ReLU등의 활성화 함수를 합성곱 계층 사이에 끼움으로써 신경망의 표현력이 개선된다. 이는 활성화 함수가 신경망에 '비선형' 힘을 가하고, 비선형 함수가 겹치면서 더 복잡한 것도 표현할 수 있게 되기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "핛브의 효율성도 층을 깊게 하는 것의 이점이다. 층을 깊게 함으로써 학습 데이터의 양을 줄여 학습을 고속으로 수행할 수 있다는 점이다.\n",
    "\n",
    "가령 CNN의 합성곱 계층이 정보를 계층적으로 추출하고 있음을 설명했다. 앞단의 합성곱 계층에서는 에지 등의 단순한 패턴에 뉴런이 더 반응하고 층이 깊어지면서 텍스처와 사물의 일부와 같이 점차 복잡한 것에 반응한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'개'를 인식하는 문제를 생각해 보자. 얕은 신경망에서 해결하려면 합성곱 계층은 개의 특징 대부분을 한번에 '이해'해야 한다. 견종도 다양하고 어느 각도에서 찍은 사진이냐에 따라 완전히 다르게 보일 수 있다. 그래서 개의 특징을 이해하려면 변화가 풍부하고 많은 학습 데이터가 필요하고, 결과적으로 학습 시간이 오래 걸린다.\n",
    "\n",
    "그러나 신경망을 깊게 하면 학습해야 할 문제를 계층적으로 분해할 수 있다. 각 층이 학습해야 할 문제를 보다 단순한 문제로 대체할 수 있는 것이다. 예를 들어 처음 층은 에지 학습에 전념하여 적은 데이터로 효율적으로 학습할 수 있다. 개가 등작하는 이미지보다 에지를 포함한 이미지는 만혹, 에지의 패턴을 개라는 패턴으로 구조가 훨씬 간단하기 때문이다.\n",
    "\n",
    "또, 층을 깊게 하면 정보를 계층적으로 전달할 수 있다는 점도 중요하다. 예를 들어 에지를 추출한 층의 다음 층은 에지 정보를 쓸 수 있고, 더 고도의 패턴을 효과적으로 학습하리라 기대할 수 있다. 즉, 층을 깊이 함으로써 각 층이 학습해야 할 문제를 '풀기 쉬운 단순한 문제'로 분해할 수 있어 효율적으로 학습하리라 기대할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 딥러닝의 초기 역사"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2012년 AlexNet이 압도적인 성적으로 우승하면서 이미지 인식에 대한 접근법을 뿌리부터 뒤흔들었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.1 이미지넷"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-7.png' width=70%>\n",
    "<center>**그림 8-7** 대규모 데이터셋 ImageNet의 데이터들</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지넷은 100만장이 넘는 이미지를 담고 있는 데이터셋이다. 각 이미지에는 레이블(클래스 이름)이 붙어 있따. 매년 열리는 ILSVRC대회에는 시험 항목이 몇 가지 있는데, 그 중 하나가 분류(classification)이다. 분류 부문에서는 1,000개의 클래스를 제대로 분류하는지를 겨룬다. 최근 분류 시험 결과는 다음과 같다. 아래는 **톱-5 오류**를 뜻하는데, 이는 확률이 가장 높다고 생각하는 후보 클래스 5개 안에 정답이 포함되지 않은, 즉 5개 모두가 틀린 비율을 뜻한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-8.png' width=70%>\n",
    "<center>**그림 8-8** ILSVRC 최우수 팀의 성적 추이: 세로축은 오류율, 가로축은 연도, 가로축의 괄호 안은 팀 이름(또는 기법 이름)</center>\n",
    "<center>이미지넷 분류 톱-5 오류</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[그림 8-8]에서 주목할 점은 2012년 이후 선두는 항상 딥러닝 방식이었다는 것이다. 실제로 2012년 AlexNet의 오류율이 크게 낮아졌고, 그 이후 딥러닝을 활ㅇ요한 기법이 꾸준히 정확도를 개선해 왔다. 특히 2015년에는 150층이 넘는 심층 신경망인 ResNet이 오류율을 3.5%까지 낮추었다. 이는 인간의 인식 능력을 넘어선 것이다. 특히 VGG, GoogLeNet, ResNet은 특히 유명하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.2 VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG는 합성곱 계층과 풀링 계층으로 구성되는 '기본적'인 CNN이다. 다만 비중 있는 층(합성곱 계층, 완전연결 계층)을 모두 16층(혹은 19층)으로 심화한 것이 특징이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-9.png' width=70%>\n",
    "<center>**그림 8-9** VGG</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG에서 주목할 점은 3 $\\times$ 3 의 작은 필터를 사용한 합성곱 계층을 연속으로 거친다는 것이다. 그림에서 보듯 합성곱 계층을 2~4회 연속으로 풀링 계층을 두어 크기를 절반으로 줄이는 처리를 반복합니다. 그리고 마지막에는 완전연결 계층을 통과시켜 결과를 출력한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE_** VGG는 2014년 대회에서 2위에 올랐다. 성능 면에서는 1위인 GoogLeNet에 뒤지지만 VGG는 구성이 간단하여 응용하기가 좋다. 그래서 많은 기술자가 VGG 기반의 신경망을 즐겨 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.3 GoogLeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GoogLeNet의 구성은 아래 그림과 같다. 그림의 사각형이 합성곱 계층과 풀링 계층등의 계층을 나타낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-10.png' width=90%>\n",
    "<center>**그림 8-10** VGG</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "매우 복잡해 보이지만 기본적으로 보아온 CNN과 다르지 않다. 단, GoogLeNet은 세로 방향 깊이뿐 아니라 가로 방향도 깊다는 점이 특징이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GoogLeNet에는 가로 방향에 '폭'이 있다. 이를 인셉션 구조라 하며, 그 기반 구조는 [그림 8-11]과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-11.png' width=80%>\n",
    "<center>**그림 8-11** GoogLeNet의 인셉션 구조</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인셉션 구조는 앞의 그림과 같이 다른 필터(와 풀링)를 여러개 적용하겨 그 결과를 결합한다. 이 인셉션 구조를 하나의 빌딩 블록(구성요소)로 사용하는 것이 GoogLeNet의 특징인 것이다. \n",
    "\n",
    "또, GoogLeNet에서는 1 $\\times$ 1 크기의 필터를 사용한 합성곱 계층을 많은 곳에서 사용한다. 이 1 $\\times$ 1 의 합성곱 연산은 채널 쪽으로 크기를 줄이는 것으로, 매개변수 제거와 고속 처리에 기여한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.4 ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ResNet**은 마이크로소프트의 팀이 개발한 네트워크이다. 그 특징은 지금까지보다 층을 더 깊게 할 수 있는 특별한 '장치'에 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보통 층을 깊게 하는 것이 성능 향상에 중요하다는 것은 알고 있지만, 딥러닝의 학습에서는 층이 지나치게 깊으면 학습이 잘 되지 않고, 오히려 성능이 떨어지는 경우도 많다. ResNet에서는 그런 문제를 해결하기 위해 **스킵 연결**(skip connection)을 도입한다. 이 구조가 층의 깊이에 비례해 성능을 향상시킬 수 있게 한 핵심이다.\n",
    "\n",
    "스킵 연결이란 [그림 8-12]와 같이 입력 데이터를 합성곱 계층을 건너뛰어 출력에 바로 더하는 구조를 말한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-12.png' width=70%>\n",
    "<center>**그림 8-12** ResNet의 구성요소: 'weight layer'는 합성곱 계층을 말한다. </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[그림 8-12]에서는 입력 x를 연속한 두 합성곱 계층을 건너뛰어 출력에 바로 연결한다. 이 단축 경로가 없었다면 두 합성곱 계층의 출력이 F(x)가 되나, 스킵 연결로 인해 F(x) + x가 되는 것이 핵심이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note_** 스킵 연결은 입력 데이터를 '그대로' 흘리는 것으로, 역전파 때도 상류의 기울기를 그대로 하류로 보낸다. 여기에서의 핵심은 상류의 기울기에 아무런 수정도 가하지 않고 '그대로' 흘린다는 것이다. 그래서 스킵 연결로 기울이가 작아지거나 지나치게 커질 걱정 없이 앞 층에 '의미 있는 기울기'가 전해지리라 기대할 수 있다. 층을 깊게 할수록 기울기가 작아지는 소실 문제를 이 스킵 연결이 줄여주는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet은 먼저 설명한 VGG 신경망을 기반으로 스킵 연결을 도입하여 층을 깊게 하였다. 그 결과는 [그림 8-13]처럼 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-13.png' width=90%>\n",
    "<center>**그림 8-13** ResNet: 블록이 3 $\\times$ 3인 합성곱 계층에 대응. 층을 건너뛰는 스킵 연결이 특징이다. </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[그림 8-13]과 같이 ResNet은 합성곱 계층을 2개 층마다 건너뛰면서 층을 깊게 한다. 실험결과 150층 이상으로 해도 정확도가 오른느 모습을 확인할 수 있다. 긜고 ILSVRC 대회에서는 톱-5 오류율이 겨울 3.5%라는 경이적인 결과를 냇다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE_** 이미지넷이 제공하는 거대한 데이터셋으로 학습한 가중치 값들은 실제 제품에 활용해도 효과적이고, 또 많이들 그렇게 이용하고 있다. 이를 **전이 학습**(transfer learning) 이라고 해서, 하긋ㅂ된 가중치(혹은 그 일부)를 다른 신경망에 복사한 다음, 그 상태로 재학습을 수행한다. 예를 들어 VGG와 구성이 같은 신경망을 준비하고, 미리 학습된 가중치를 초깃값으로 설정한 후, 새로운 데이터셋을 대상으로 재학습(fine tuning)을 수행한다. 전이 학습은 보유한 데이터셋이 적을 때 특히 유용한 방법이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 더 빠르게(딥러닝 고속화)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "빅 데이터와 네트워크의 발전으로 딥러닝에서는 대량의 연산을 수행해야 한다. 과거에는 주로 CPU가 곗나을 담당했으나, CPU만으로 딥러닝을 처리하기에는 부족한게 현실이다. 실제로 주위를 둘러보면 딥러닝 프레임워크 대부분은 **GPU**를 활용해 대량의 연산을 고속으로 처리할 수 있다.\n",
    "\n",
    "최근 프레임워크에서는 학습을 복수의 GPU와 여러 기기로 분산 수행하기 시작했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.1 풀어야 할 숙제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝의 고속화 애기를 시작하기에 앞서, 딥러닝에서는 어떠한 처리에 시간이 소요되는지를 보자. [그림 8-14]는 AlexNet의 forward 처리(순전파)에서 각 층이 소비하는 시간을 원 그래프로 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-14.png' width=90%>\n",
    "**그림 8-14** AlexNet의 forward 처리 시 각 층의 시간 비율: 왼쪽이 GPU, 오른쪽이 CPU를 사용한 경우. 'conv'는 합성곱 계층. 'pool'은 풀링 계층, 'fc'는 완전연결 계층, 'norm'은 정규화 계층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그림에서 보듯 AlexNet엣는 오랜 시간을 합성곱 계층에서 소요한다. 실제로 합성곱 계층의 처리 시간을 다 더하면 GPU에서는 전체의 95%, CPU에서는 전체의 89%까지 달한다. 그래서 합성곱 계층에서 이뤄지는 연ㅅ나을 어떻게 고속으로 효율적으로 하느냐가 딥런닝의 과제이다. [그림 8-14]는 추론 때의 결과이지만, 학습 시에도 마찬가지로 합성곱 계층에서 많은 시간을 소비하게 된다.\n",
    "\n",
    "**NOTE_** 합성곱 계층에서 수행하는 연산은 \"7.2 합성곱 계층\"에서 설명했듯이, 결국 '단일 곱셉-누산'이다. 그래서 딥러닝 고속화라는 것은 결국 대량의 '단일 곱셈-누산'을 어떻게 고속으로 효율적으로 계산하느냐는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.2 GPU를 활용한 고속화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU는 원래 그래픽 전용 보드에 이용되어 왔다. 그러나 최근에는 그래픽 처리뿐 아니라 범용 수치 연산에도 이용된다. GPU는 병렬수치 연산을 고속으로 처리할 수 있으니, 그 압도적인 힘을 다양한 용도로 활용하자는 것이 **GPU 컴퓨팅**의 목적이다. 이처럼 GPU로 범용 수치 연산을 수행하는 것을 GPU 컴퓨팅이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU는 원래 그래픽 전용 보드에 이용해왔지만, 최근에는 그래픽 처리뿐 아니라 범용 수치 연산에도 이용한다. GPU는 병렬 수치 연산을 고속으로 처리할 수 있으니, 그 압도적인 힘을 다양한 용도로 활용하자는 것이 **GPU 컴퓨팅**의 목적이다. 이처럼 GPU로 범용 수치연산을 수행하는 것을 GPU 컴퓨팅이라고 한다.\n",
    "\n",
    "딥러닝에서는 대량의 단일 곱셈-누산(또는 큰 행렬의 내적)을 수행해야 한다. 이러한 대량 병렬 연산은 GPU의 특기다. (반대로 CPU는 연속적인 복잡한 계산을 잘 처리한다.) 그래서 딥러닝 연산에서는 GPU를 이용하면 CPU만 쓸 때보다 놀라울 정도로 빠르게 결과를 얻을 수 있다. 시간 비교 결과는 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-15.png' width=70%>\n",
    "<center>**그림 8-15** AlexNet의 학습 시간을 비교한 결과</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그림과 같이 CPU로 40일 걸리던 일이 GPU로는 6일이 단축되었고, 또 cuDNN이라는 딥러닝에 최적화된 라이브러리를 이용하면 더욱 빨라진다.\n",
    "\n",
    "엔비디아 GPU에서는 **CUDA**라는 엔비디아의 GPU 컴퓨팅용 통합 개발 환경을 사용한다. **cuDNN**은 CUDA 위에서 동작하는 라이브러리로, 딥러닝에 최적화된 함수 등이 구현되어 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE_** 합성곱 계층에서 행하는 연산은 im2col을 이용해 큰 행렬의 내적으로 변환할 수 있었다. 이러한 im2col의 방식은 GPU로 구현하기에도 적잡하다. GPU는 '작은' 단위로 계산하기보다는 큰 덩어리를 한 번에 계산하는데 유리하기 때문이다. 즉, im2col로 거대한 행렬의 내적으로 한번에 계산하여 GPU의 잠재력을 끌어내는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.3 분산 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-16.png' width=70%>\n",
    "<center>**그림 8-16** 텐서플로의 분산 학습 성능 : 가로는 GPU의 수, 세로는 GPU 1개일 때와 비교한 비율</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분산 학습에서도 '계산을 어떻게 분산시키냐'는 매우 어려운 문제이다. 컴퓨터 사이의 통신과 데이터 사이의 동기화 등, 쉽게 해결할 수 없는 문제를 끌어안고 있기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.4 연산 정밀도와 비트 줄이기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "계산 능력 외에도 메모리 용량과 버스 대역폭이 딥러닝 고속화에 병목이 될 수 있다. 메모리 용량 면에서는 대량의 가중치 매개변수와 중간 데이터를 메모리에 저장해야 한다는 것을 생각해야 한다. 버스 대역폭 면에서는 GPU(혹은 CPU)의 버스를 흐르는 데이터가 많아져 한계를 넘어서면 병목이 된다. 이런 경우를 고려하면 네트워크로 주고받는 데이터의 비트 수는 최소로 만드는 것이 바람직하다.\n",
    "\n",
    "컴퓨터에서는 주로 64비트나 32비트 부동소수점 수를 사용해 실수를 표현한다. 많은 비트를 사용할수록 계산 오차는 줄어들지만, 그만큼 계산에 드는 비용과 메모리 사용량이 늘고 버스 대역폭에 부담을 준다.\n",
    "\n",
    "다행히 신경망은 높은 수치 정밀도(수치를 몇 비트로 표현하느냐)를 요구하지는 않는다. 이는 신경망의 중요한 성질 중 하나로, 신경망의 견고성에 따른 특성이다. 예를 들어 신경망은 입력 이미지에 노이즈가 조금 섞여 있어도 출력 결과가 잘 달라지지 않는 강건함을 보여준다. 이런 견고성 덕분에 신경망을 흐르는 데이터를 '퇴화'시켜도 출력에 주는 영향은 적다.\n",
    "\n",
    "컴퓨터에서 실수를 표현하는 방식으로 **32비트 단정밀도**(single-precision)와 **64비트 배정밀도**(double-precision) 부동소수점 등의 포맷이 있지만, 지금까지의 실험으로는 딥러닝은 **16비트 반정밀도**(half-precision)만 사용해도 학습에 문제가 없다고 알려져 있다. 실제로 엔비디아의 최신 GPU인 **파스칼** 아키텍처는 이 포멧을 지원하여, 이제는 반정밀도 부동소수점이 표준적으로 이용되리라 생각된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE__** 엔비디아의 맥스웰(Maxwell) 세대 GPU는 반정밀도 부동소수점 수를 스토리지(데이터를 저장하는 기능)로 지원하고 있었지만, 연산 자체는 16비트로 수행하지 않았다. 이것이 파스칼 세대에 와서 연산 역시 16비트로 하기 시작하여, 이전 세대보다 2배정도 빨라질 것으로 기대된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적으로 파이썬은 64비트 배정밀도 부동소수점 수를 사용한다. 하지만 넘파이는 16비트 반정밀도 부동소수점도 지원하며, 이를 사용해도 정확도가 떨어지지 않는 것을 확인할 수 있었다. 하지만 넘파이는 16비트 반정밀도 부동소수점도 지원하며, 이를 사용해도 정확도가 떨어지지 않는 것을 쉽게 확인할 수 있었다.\n",
    "\n",
    "딥러닝의 비트 수를 줄이는 연구가 몇가지 진행되고 있다. 최근에는 가중치와 중간데이터를 1비트로 표현하는 < Binarized Neural Networks > 라는 방법도 등장했다. 딥러닝을 고속화하기 위해 비트를 줄이는 기술은 앞으로 주시해야 할 분야이며, 특히 딥러닝을 임베디드용으로 이용할 때 중요한 주제이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4 딥러닝의 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사물 검출은 [그림 8-17]과 같이 이미지 속에 담긴 사물의 위치와 종류(클래스)를 알아내는 기술이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-17.png' width=70%>\n",
    "<center>**그림 8-17** 사물 검출의 예</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 그림에서 보듯, 사물 검출은 사물 인식보다 어려운 문제이다. 지금까지 본 사물 인식은 이미지 전체를 대상으로 했는데, 사물 검출에서는 이미지 어딘가에 있을 사물의 위치까지 알아내야 한다. 게다가 한 이미지에 여러 사물이 존재할 수도 있다.\n",
    "\n",
    "이런 사물 검출 문제에 CNN을 기반으로 한 기법이 몇 가지 제안되었다. 이들 기법이 발군의 성능을 보여 사물 검출에도 딥러닝이 효과적임이 입증되었다.\n",
    "\n",
    "CNN을 이용하여 사물 검출을 수행하는 방식은 몇 가지가 있는데, 그중에서도 **R-CNN**(Regions with Convolutional Neural Network)이 유명하다. [그림 8-18]은 R-CNN의 처리 흐름이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-18.png' width=70%>\n",
    "<center>**그림 8-18** R-CNN의 처리 흐름</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-CNN 그림에서 주목할 곳은 '2. 후보 영역 추출'과 '3. CNN 특징 계산' 이다. 먼저 사물이 위치한 영역을 (어떤 방법으로) 찾아내고, 추출한 각 영역에 CNN을 적용하여 클래스를 분류하는 것이다. 여기서 이미지를 사각형으로 변형하거나 분류할 때 서포트 벡터 머신(SVM)을 사용하는 등 실제 처리흐름은 다소 복잡하지만, 큰 틀에서는 이들 두 처리(후보 영역 추출과 CNN 특징 계산)로 구성된다.\n",
    "\n",
    "후보 영역 추출(사물처럼 보이는 물체를 찾아 처리)에는 컴퓨터 비전 분야에서 발전해온 다양한 기법을 사용할 수 있고, R-CNN 논문에서는 Selective Search 기법을 사용했다. 최근에는 이 후보 영역 추출까지 CNN으로 처리하는 Faster R-CNN 기법도 등장했다. Faster R-CNN은 모든 일을 하나의 CNN에서 처리하기 때문에 아주 빠르다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4.2 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**분할**(segmentation)이란 이미지를 픽셀 수준에서 분류하는 문제이다. [그림 8-10]와 같이 픽셀 단위로 개체마다 채색된 지도(supervised) 데이터를 사용해 학습한다. 그리고 추론할 때 입력 이미지의 모든 픽셀을 분류한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-19.png' width=70%>\n",
    "<center>**그림 8-19** 분할의 예: 왼쪽이 입력 이미지, 오른쪽이 지도용 이미지</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지 구현한 신경망은 분류를 이미지 전체를 대상으로 해 왔다. 이를 픽셀 수준에 적용하려면 어떻게 해야 할까?\n",
    "\n",
    "신경망을 이용해 분할하는 가장 단순한 방법은 모든 픽셀의 클래스를 분류하는 신경망을 만들어서, 모든 픽셀을 대상으로 하나씩 추론 작업을 실행하는 것이다. 짐작한 대로 이런 식으로는 픽셀의 수만큼 forward 처리를 해야 하여 긴 시간이 걸리게 된다. (정확히는 합성곱 연산에서 많은 영역을 쓸데없이 다시 계산하는 것이 문제가 된다.)\n",
    "\n",
    "이러한 낭비를 줄여주는 기법으로 FCN(Fully convolutional Network)가 고안되었다. 이는 단 한번의 forward처리로 모든 픽셀의 클래스를 분류해주는 놀라운 기법이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-20.png' width=70%>\n",
    "<center>**그림 8-20** FCN의 전체 그림</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fully Convolutioanl Network를 직역하면 '합성곱 계층만으로 구성된 네트워크'가 된다. 일반적인 CNN이 완전연결 계층을 이용하는 반면, FCN은 이 완전연결 계층을 '같은 기능을 하는 합성곱 계층' 으로 바꾼다. 사물 인식에서 사용ㅎ나 신경망의 완전연결 계층에서는 중간 데이터의 공간 볼륨(다차원 형태)을 1차원으로 변환하여 한 줄로 늘어선 노드들이 처리했으나, FCN에서는 공간 볼륨을 유지한 채 마지막 출력까지 처리할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FCN은 [그림 8-20]에서 보듯 마지막에 공간 크기를 확대하는 처리를 도입했다는 것도 특징이다. 이 확대 처리로 인해 줄어든 중간  데이터를 입력 이미지와 같은 크기까지 단번에 확대할 수 있다. FCN의 마지막에 수행하는 확대는 이중 선형 보간(bilinear iterpolation)에 의한 선형 확대이다. FCN에서는 이 선형 확대를 역합성곱(deconvolution) 연산으로 구현해내고 있다. (자세한 내용은 FCN 논문을 참조)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE_** 완전연결 계층에서는 출력이 모든 입력과 연결된다. 이와 같은 구성을 합성곱 계층으로도 구현할 수 있다. 가령 입력 크기가 32 $\\times$ 10 $\\times$ 10 (채널 32개, 높이 10, 너비 10)인 데이터에 대한 완전연결 계층은 필터 크기가 32 $\\times$ 10 $\\times$ 10인 합성곱 계층으로 대체할 수 있다. 만약 완전연결 계층의 출력 노드가 100개라면 합성곱 계층에서는 기존의 32 $\\times$ 10 $\\times$ 10 필터를 100개 준비하면 완전히 같은 처리를 할 수 있따. 이처럼 완전연결 계층은 같은 일을 수행하는 합성곱 계층으로 대체할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4.3 사진 캡션 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-21.png' width=70%>\n",
    "<center>**그림 8-21** 딥러닝으로 사진 캡션을 생성하는 예</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 딥러닝으로 사진 캡션을 생성하는 방법으로는 NIC(Neural Image Caption)모델이 대표적이다. NIC는 [그림 8-22]와 같이 심층 CNN과 자연어를 다루는 **순환 신경망**으로 구성된다. RNN은 순환적 관곌를 갖는 신경망으로 자연어나 시계열 데이터등의 연속된 데이터를 다룰 때 많이 활용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-22.png' width=60%>\n",
    "<center>**그림 8-22** NIC의 전체 구성</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NIC는 CNN으로 사진에서 특징을 추출하고, 그 특징을 RNN에 넘긴다. RNN은 CNN이 추출한 특징을 초깃갑승로 해서 텍스트를 '순환적'으로 생성한다. 여기에서는 더 이상의 상세 기술을 설명하지 않지만, 기본적으로 NIC는 2개의 신경망(CNN과 RNN)을 조합한 간단한 구성이다. 그래서 놀라울 정도로 정확한 사진 캡션을 만들어내는 것이다. 또한, 사진이나 자연어와 같은 여러 종류의 정보를 조합하고 처리하는 것을 **멀티모달 처리**(multimodal processing)라고 하여, 최근 주목받는 분야 중 하나이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE_** RNN의 R은 Recurrent(순환적)을 의미한다. 여기서 순환은 신경망의 순환적 네트워크 구조를 말한다. 이 순환적인 구조로 인해 이전에 생성한 정보에 영향을 받는(바꾸어 말하면, 과거의 정보를 기억하는)점이 RNN의 특징이다. 예를 들어 '나'라는 단어를 생성한 뒤 '잤다'라는 단어를 생성하면 먼저 만든 '나'의 영향을 받아 '는'이라는 조사가 자동으로 생성되어, 최종적으로 '나는 잤다'라는 문장이 완성되는 식이다. 이처럼 자연어와 시계열 데이터 등 연속성 있는 데이터를 다룰 때 RNN은 과거의 정보를 기억하면서 동작한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5 딥러닝의 미래"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.1 이미지 스타일(화풍) 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝을 활용해 화가처럼 '그림을 그리는' 연구가 있다. 아래 그림은 두 이미지를 입력해서 새로운 그림을 생성하는 연구이다. 하나는 '콘텐츠 이미지', 다른 하나는 '스타일 이미지'라 부르는데, 이 둘을 조합해 새로운 그림을 그려준다.\n",
    "\n",
    "아래 그림과 같이 고흐의 화풍을 콘텐츠 이미지에 적용하도록 지정하면, 이를 기초로 딥러닝이 새로운 그림을 그린다. 이 기법을 담은 A Neural Algorithm of Artistic Style 논문은 발표되자마자 전 세계에서 많은 이목을 끌었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-23.png' width=60%>\n",
    "**그림 8-23** A Neural Algorithm of Artistic Style 논문을 구현해 적용한 예: 왼쪽 위가 '스타일 이미지', 오른쪽 위가 '콘텐츠 이미지', 아래가 새로 생성한 이미지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 기술은 네트워크의 중간 데이터가 콘텐츠 이미지의 중간 데이터와 비슷하도록 학습한다. 이렇게 하면 입력 이미지를 콘텐츠 이미지의 형태를 흉내낼 수 있다. 또, 스타일 이미지의 화풍을 흡수하기 위해 '스타일 행렬'이라는 개념을 도입한다. 그 스타일 행렬의 오차를 줄이도록 학습하여 입력 이미지를 고흐의 화풍과 비슷해지게 만들 수 있는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.2 이미지 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞의 이미지 스타일 변환 예는 새로운 그림을 생성하려면 이미지 두 장을 입력해야 했다. 한편 아무런 입력 이미지 없이도 새로운 이미지를 그려내는 연구도 진행 중이다. 물론 먼저 대량의 이미지를 사용하여 학습하긴 하지만, 학습이 끝난 후에는 아무런 입력 이미지 없이도 새로운 그림을 그려낸다. 가령 딥러닝으로 '침실' 이미지를 무로부터 생성하는게 가능하다. **DCGAN** 기법으로 생성한 침실 이미지들이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-24.png' width=60%>\n",
    "<center>**그림 8-24** DCGAN으로 새롭게 생성한 침실 이미지들</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "진짜와 구분할 수 없는 수준의 이미지를 그리는 DCGAN은 이미지를 생성하는 과정을 모델화한다. 그 모델을 대량의 이미지(가령 침실이 찍힌 대량의 이미지)를 사용해 학습하고, 학습이 끝나면 그 모델을 이용하여 새로운 그림을 생성할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DCGAN도 딥러닝을 사용한다. DCGAN 기술의 핵십은 생성자(generator)와 식별자(discrimiator)로 불리는 2개의 신경망을 이용한다는 점이다. 생성자가 진짜와 똑같은 이미지를 생성하고 식별자는 그것이 진짜인지(생성자가 생성한 이미징니지, 아니면 실제로 촬영된 이미지인지)를 판정한다. 그렇게 해서 둘을 겨루도록 학습시켜, 생성자는 더 정교한 가짜 이미지 생성 기술을 학습하고 식별자는 더 정확하게 간파할 수 있는 감정사로 성장하는 것이다. 이렇게 둘의 능력을 부지런히 갈고닦게 한다는 개념이 **GAN** 기술의 재미난 점이다. 그렇게 절차탁마해서 생성한 생성자는 최종적으로 진짜와 착각할 정도의 이미지를 그려내는 능력을 기른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE_** 이전까지 살펴본 기계학습 문제는 **지도 학습**(supervised learning)이라는 유형의 문제였다. 지도학습은 손글씨 숫자 인식처럼 이미지 데이터와 정답 레이블을 짝지은 데이터셋을 이용한다. 그러나 이번 절에서 거론한 문제는 지도용 데이터는 주어지지 않고, 단지 대량의 이미지(이미지의 집합)만 주어진다. 즉, 지도 없이 스스로 학습하는 **자율 학습**(unsupervised learning)문제이다. 자율 학습은 비교적 오래전부터 연구된 분야지만 최근에는 그다지 활발하게 연구되지는 않는다는 느낌이다. 최근 딥러닝을 사용한 DCGAN등과 같은 기법이 시선을 끌면서, 앞으로 자율 학습도 새로운 도약을 기대할 수 있을지도 모른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.3 자율 주행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SegNet**이라는 CNN기반 신경망은 아래 그림과 같이 주변 환경을 정확하게 인식해낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-25.png' width=60%>\n",
    "<center>**그림 8-25** 딥러닝을 활용한 이미지 분할의 예: 도로, 차, 건물, 인도 등을 정확하게 인식한다.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.4 Deep Q-Network(강화학습)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(자전거를 배울 때처럼) 사람이 시행착오를 겪으며 배우듯 컴퓨터도 시행착오 과정에서 스스로 학습하게 하려는 분야가 있다. 이는 '가르침'에 의존하는 '지도 학습'과는 다른 분야로, **강화학습**(reinforcement learning)이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "강화학습에서는 에이전트라는 것이 환경에 맞게 행동을 선택하고, 그 행동에 의해서 환경이 변한다는게 기본적인 틀이다. 환경이 변화하면 에이전트는 어떠한 보상을 얻는다. 강화학습의 목적은 더 나은 보상을 받는 쪽응로 에이전트의 행동 지침을 바로잡는 것이다. (그림 8-26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-26.png' width=40%>\n",
    "<center>**그림 8-26** 강화학습의 기본 틀 : 에이전트는 더 좋은 보상을 받기 위해 스스로 학습한다.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위는 강화학습의 기본 틀이다. 여기에서 주의할 점은 보상은 정해진 것은 아니라, '예상 보상'이라는 점이다. 예를 들면 <슈퍼마리오 브라더스>에서 마리오를 오른쪽으로 이동했을 때 얻는 보상이 항상 명확한 것은 아니다. 어떤 상황에서 이동한 것이냐에 따라 보상은 천차만별이 될 수 있다. 이런 불명확한 상황에서는 게임 점수(동전을 먹거나 적을 쓰러트리는 등)나 게임 종료 등의 명확한 지표로부터 역산해서 '예상 보상'을 정해야 한다. 만약 지도 학습이었다면 행동에 대한 '지도'를 통해 올바른 평가를 받을 수 있었을 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝을 사용한 강화학습 중 Deep Q-Network(일명 DQN)이라는 방법이 있다. 이는 Q학습이라는 강화학습 알고리즘을 기초로 한다. Q학습에서는 최적 행동 가치 함수로 최적인 행동을 정한다. 이 함수를 딥러닝(CNN)으로 비슷하게 흉내 내어 사용하는 것이 DQN이다.\n",
    "\n",
    "DQN 연구 중에는 비디오 게임을 자율 학습시켜 사람을 뛰어넘는 수준의 조작을 실현한 사례가 보고되고 있다. [그림 8-27]과 같이 DQN에서 사용하는 CNN은 게임 영상 프레임(4개의 연속한 프레임)을 입력하여 최종적으로는 게임을 제어하는 움직임(조이스틱 이동량이나 버튼 조작 여부)에 대해서 각 동작의 '가치'를 출력한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./deep_learning_images/fig 8-27.png' width=70%>\n",
    "<center>**그림 8-27** Deep Q-Network로 비디오 게임 조작을 학습한다. 비디오 게임 영상을 입력받아 시행착오를 거쳐 프로게이머 뺨치는 게임 컨트롤을 학습한다.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그동안의 비디오 게임 학습에서는 게임의 상태(케릭터 위치)등이 미리 추출되어야 하였다. 하지만 DQN에서는 그림과 같이 입력 데이터는 비디오 게임의 영상뿐이다. 이는 DQN의 주목할 점으로, DQN의 응용 가능성을 현격히 높였다고 할 수 있다. 게임마다 설정을 바꿀필요없이 단순히 DQN에 게임 영상을 보여주기만 하면 된다. 실제 DQN은 구성을 변경하지 않고도 팩맨과 아타리 같은 많은 게임을 학습할 수 있으며, 수많은 게임에서 사람보다 뛰어난 성적을 거두고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE_** 알파고는 3,000만개의 프로 기보를 보고 학습한 후, 알파고 스스로 자신과 맞붙는 대결을 반복하면서 수련하였다. 또한, 알파고와 DQN은 모두 구글이 인수한 딥마인드가 진행한 연구이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.6 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 장에서 배운 내용\n",
    "- 수많은 문제에서 신경망을 더 깊게 하여 성능을 개선할 수 있다.\n",
    "- 이미지 인식 기술 대회인 ILSVRC에서는 최근 딥러닝 기반 기법이 상위권을 독점하고 있으며, 그 깊이도 더 깊어지는 추세이다.\n",
    "- 유명한 신경망으로는 VGG, GoogLeNet, ResNet이 있다.\n",
    "- GPU와 분산 학습, 비트 정밀도 감소 등으로 딥러닝을 고속화할 수 있다.\n",
    "- 딥러닝(신경망)은 사물 인식뿐 아니라 사물 검출과 분할에도 이용할 수 있다.\n",
    "- 딥러닝의 응용 분야로는 사진의 캡션 생성, 이미지 생성, 강화학습 등이 있다. 최근에는 자율 주행에도 딥러닝을 접목하고 있어 기대된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
